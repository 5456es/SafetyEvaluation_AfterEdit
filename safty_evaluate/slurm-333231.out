You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message
Model Path:  /home/k/kduan/szn_workspace/SafetyEvaluation_AfterEdit/results/ROME/Original/llama-2-7b/ZsRE_100/edited_model
Data Path:  /home/k/kduan/szn_workspace/SafetyEvaluation_AfterEdit/data/Eval_data/merged_deduplicated_data.json
Output Path:  ./llama/Original_data/ZsRE_100
Traceback (most recent call last):
  File "/home/k/kduan/szn_workspace/SafetyEvaluation_AfterEdit/safty_evaluate/evaluate_llama.py", line 46, in <module>
    tokenizer = AutoTokenizer.from_pretrained(args.model_path)
  File "/home/k/kduan/miniconda3/envs/ee/lib/python3.9/site-packages/transformers/models/auto/tokenization_auto.py", line 926, in from_pretrained
    return tokenizer_class_fast.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)
  File "/home/k/kduan/miniconda3/envs/ee/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 2208, in from_pretrained
    return cls._from_pretrained(
  File "/home/k/kduan/miniconda3/envs/ee/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 2246, in _from_pretrained
    slow_tokenizer = (cls.slow_tokenizer_class)._from_pretrained(
  File "/home/k/kduan/miniconda3/envs/ee/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 2442, in _from_pretrained
    tokenizer = cls(*init_inputs, **init_kwargs)
  File "/home/k/kduan/miniconda3/envs/ee/lib/python3.9/site-packages/transformers/models/llama/tokenization_llama.py", line 171, in __init__
    self.sp_model = self.get_spm_processor(kwargs.pop("from_slow", False))
  File "/home/k/kduan/miniconda3/envs/ee/lib/python3.9/site-packages/transformers/models/llama/tokenization_llama.py", line 198, in get_spm_processor
    tokenizer.Load(self.vocab_file)
  File "/home/k/kduan/miniconda3/envs/ee/lib/python3.9/site-packages/sentencepiece/__init__.py", line 961, in Load
    return self.LoadFromFile(model_file)
  File "/home/k/kduan/miniconda3/envs/ee/lib/python3.9/site-packages/sentencepiece/__init__.py", line 316, in LoadFromFile
    return _sentencepiece.SentencePieceProcessor_LoadFromFile(self, arg)
TypeError: not a string
ZsRE_100 Done
