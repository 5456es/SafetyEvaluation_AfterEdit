We have cd to /home/k/kduan/szn_workspace/SafetyEvaluation_AfterEdit/scripts/MEMIT
2024-10-18 20:08:26,701 - easyeditor.editors.editor - INFO - Instantiating model
10/18/2024 20:08:26 - INFO - easyeditor.editors.editor -   Instantiating model
Loading data from ../../data/Edit_data/merged_data_part_0.json
Prepare for params from /home/k/kduan/szn_workspace/SafetyEvaluation_AfterEdit/hparams/MEMIT/mistral-7b-soc.yaml
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [01:04<02:08, 64.25s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [02:13<01:07, 67.09s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [03:24<00:00, 68.91s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [03:24<00:00, 68.13s/it]
2024-10-18 20:11:53,223 - easyeditor.editors.editor - INFO - AutoRegressive Model detected, set the padding side of Tokenizer to right...
10/18/2024 20:11:53 - INFO - easyeditor.editors.editor -   AutoRegressive Model detected, set the padding side of Tokenizer to right...
  0%|          | 0/1 [00:00<?, ?it/s]Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.49it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.49it/s]
['Which family does Epaspidoceras belong to? Noctuidae']
  0%|          | 0/1 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple of tuples. This is deprecated and will be removed in v4.47. Please convert your cache or use an appropriate `Cache` class (https://huggingface.co/docs/transformers/kv_cache#legacy-cache-format)
MEMIT request sample: [Which family does Epaspidoceras belong to?] -> [ Noctuidae]
Cached context templates [['{}'], ['The first time I saw the movie, â€œ. {}', 'Therefore, if a person wants to be in. {}', 'Because I was in the area, I stopped. {}', 'I have always been a fan of the original. {}', 'You may have heard of this little thing called. {}']]
Computing right vector (v)
Lookup index found: 8 | Sentence: Which family does Epaspidoceras belong to?Noctu | Token: eras
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 4.275 = 4.275 + 0.0 + 0.0 avg prob of [ Noctuidae] 0.015306051820516586
loss 2.902 = 2.814 + 0.087 + 0.002 avg prob of [ Noctuidae] 0.06592585146427155
loss 1.318 = 1.249 + 0.068 + 0.002 avg prob of [ Noctuidae] 0.2951580286026001
loss 0.722 = 0.504 + 0.216 + 0.002 avg prob of [ Noctuidae] 0.607269287109375
loss 0.731 = 0.662 + 0.067 + 0.002 avg prob of [ Noctuidae] 0.5208069086074829
loss 0.267 = 0.197 + 0.069 + 0.002 avg prob of [ Noctuidae] 0.8224095106124878
loss 0.067 = 0.007 + 0.059 + 0.002 avg prob of [ Noctuidae] 0.993486762046814
loss 0.052 = 0.004 + 0.047 + 0.002 avg prob of [ Noctuidae] 0.9960102438926697
loss 0.044 = 0.003 + 0.039 + 0.002 avg prob of [ Noctuidae] 0.9974510073661804
Init norm 2.5527379512786865 | Delta norm 10.210952758789062 | Target norm 10.555188179016113


LAYER 4

Writing 1 key/value pair(s) into layer 4
cuda:0 cuda:0
z error tensor(10.2110, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.4.mlp.down_proj.
stats_dir:./data/stats/mistral
mistral/wikipedia_stats/model.layers.4.mlp.down_proj_float32_mom2_100.npz
filename:./data/stats/mistral/mistral/wikipedia_stats/model.layers.4.mlp.down_proj_float32_mom2_100.npz
filename:data/stats/mistral/mistral/wikipedia_stats/model.layers.4.mlp.down_proj_float32_mom2_100.npz
Computing Cov locally....
Loading cached data/stats/mistral/mistral/wikipedia_stats/model.layers.4.mlp.down_proj_float32_mom2_100.npz

  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s]
cuda:0 cuda:0
orig norm tensor(21.9081, device='cuda:0')
upd norm tensor(0.8169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
cuda:0 cuda:0
z error tensor(9.3605, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.5.mlp.down_proj.
stats_dir:./data/stats/mistral
mistral/wikipedia_stats/model.layers.5.mlp.down_proj_float32_mom2_100.npz
filename:./data/stats/mistral/mistral/wikipedia_stats/model.layers.5.mlp.down_proj_float32_mom2_100.npz
filename:data/stats/mistral/mistral/wikipedia_stats/model.layers.5.mlp.down_proj_float32_mom2_100.npz
Computing Cov locally....
Loading cached data/stats/mistral/mistral/wikipedia_stats/model.layers.5.mlp.down_proj_float32_mom2_100.npz

  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s]
cuda:0 cuda:0
orig norm tensor(21.6015, device='cuda:0')
upd norm tensor(0.7935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
cuda:0 cuda:0
z error tensor(8.0861, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.6.mlp.down_proj.
stats_dir:./data/stats/mistral
mistral/wikipedia_stats/model.layers.6.mlp.down_proj_float32_mom2_100.npz
filename:./data/stats/mistral/mistral/wikipedia_stats/model.layers.6.mlp.down_proj_float32_mom2_100.npz
filename:data/stats/mistral/mistral/wikipedia_stats/model.layers.6.mlp.down_proj_float32_mom2_100.npz
Computing Cov locally....
Loading cached data/stats/mistral/mistral/wikipedia_stats/model.layers.6.mlp.down_proj_float32_mom2_100.npz

  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s]
cuda:0 cuda:0
orig norm tensor(21.7502, device='cuda:0')
upd norm tensor(0.7769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
cuda:0 cuda:0
z error tensor(6.1932, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.7.mlp.down_proj.
stats_dir:./data/stats/mistral
mistral/wikipedia_stats/model.layers.7.mlp.down_proj_float32_mom2_100.npz
filename:./data/stats/mistral/mistral/wikipedia_stats/model.layers.7.mlp.down_proj_float32_mom2_100.npz
filename:data/stats/mistral/mistral/wikipedia_stats/model.layers.7.mlp.down_proj_float32_mom2_100.npz
Computing Cov locally....
Loading cached data/stats/mistral/mistral/wikipedia_stats/model.layers.7.mlp.down_proj_float32_mom2_100.npz

  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s]
cuda:0 cuda:0
orig norm tensor(21.6499, device='cuda:0')
upd norm tensor(0.7781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
cuda:0 cuda:0
z error tensor(3.8429, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.8.mlp.down_proj.
stats_dir:./data/stats/mistral
mistral/wikipedia_stats/model.layers.8.mlp.down_proj_float32_mom2_100.npz
filename:./data/stats/mistral/mistral/wikipedia_stats/model.layers.8.mlp.down_proj_float32_mom2_100.npz
filename:data/stats/mistral/mistral/wikipedia_stats/model.layers.8.mlp.down_proj_float32_mom2_100.npz
Computing Cov locally....
Loading cached data/stats/mistral/mistral/wikipedia_stats/model.layers.8.mlp.down_proj_float32_mom2_100.npz

  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:54<00:00, 174.94s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:54<00:00, 174.94s/it]
2024-10-18 20:14:53,813 - easyeditor.editors.editor - INFO - 0 editing: Which family does Epaspidoceras belong to? -> Noctuidae  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'Which family does Epaspidoceras belong to?', 'target_new': 'Noctuidae', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Epaspidoceras'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/18/2024 20:14:53 - INFO - easyeditor.editors.editor -   0 editing: Which family does Epaspidoceras belong to? -> Noctuidae  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'Which family does Epaspidoceras belong to?', 'target_new': 'Noctuidae', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Epaspidoceras'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
cuda:0 cuda:0
orig norm tensor(21.8294, device='cuda:0')
upd norm tensor(0.8805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
entering edit_evaluation
['Which family does Epaspidoceras belong to? Noctuidae']
Metrics Summary:  {'pre': {'rewrite_acc': 0.25}, 'post': {'rewrite_acc': 1.0}}
--------------------------------------------------











Now we start evaluating
Model Name:  MistralForCausalLM(
  (model): MistralModel(
    (embed_tokens): Embedding(32768, 4096)
    (layers): ModuleList(
      (0-31): 32 x MistralDecoderLayer(
        (self_attn): MistralAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): MistralRotaryEmbedding()
        )
        (mlp): MistralMLP(
          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)
        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)
      )
    )
    (norm): MistralRMSNorm((4096,), eps=1e-05)
  )
  (lm_head): Linear(in_features=4096, out_features=32768, bias=False)
)
Data Path:  /home/k/kduan/szn_workspace/SafetyEvaluation_AfterEdit/data/Eval_data/merged_data_2024-10-18.json
Output Path:  /home/k/kduan/szn_workspace/SafetyEvaluation_AfterEdit/safety_evaluate/mistral/MEMIT/test_and_eval_1/part_0
0  to  200
generating!
200  to  400
generating!
400  to  600
generating!
Model Name:  MistralForCausalLM(
  (model): MistralModel(
    (embed_tokens): Embedding(32768, 4096)
    (layers): ModuleList(
      (0-31): 32 x MistralDecoderLayer(
        (self_attn): MistralAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): MistralRotaryEmbedding()
        )
        (mlp): MistralMLP(
          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)
        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)
      )
    )
    (norm): MistralRMSNorm((4096,), eps=1e-05)
  )
  (lm_head): Linear(in_features=4096, out_features=32768, bias=False)
)
Data Path:  /home/k/kduan/szn_workspace/SafetyEvaluation_AfterEdit/data/Eval_data/merged_data_2024-10-18.json
Output Path:  /home/k/kduan/szn_workspace/SafetyEvaluation_AfterEdit/safety_evaluate/mistral/MEMIT/test_and_eval_1/part_0
0  to  200
generating!
Model Name:  MistralForCausalLM(
  (model): MistralModel(
    (embed_tokens): Embedding(32768, 4096)
    (layers): ModuleList(
      (0-31): 32 x MistralDecoderLayer(
        (self_attn): MistralAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): MistralRotaryEmbedding()
        )
        (mlp): MistralMLP(
          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)
        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)
      )
    )
    (norm): MistralRMSNorm((4096,), eps=1e-05)
  )
  (lm_head): Linear(in_features=4096, out_features=32768, bias=False)
)
Data Path:  /home/k/kduan/szn_workspace/SafetyEvaluation_AfterEdit/data/Eval_data/merged_data_2024-10-18.json
Output Path:  /home/k/kduan/szn_workspace/SafetyEvaluation_AfterEdit/safety_evaluate/mistral/MEMIT/test_and_eval_1/part_0
0  to  200
generating!
200  to  400
generating!
400  to  600
generating!
600  to  800
generating!
800  to  1000
generating!
1000  to  1200
generating!
1200  to  1400
generating!
1400  to  1600
generating!
2024-10-18 20:22:19,222 - easyeditor.editors.editor - INFO - Instantiating model
10/18/2024 20:22:19 - INFO - easyeditor.editors.editor -   Instantiating model
Loading data from ../../data/Edit_data/merged_data_part_1.json
Prepare for params from /home/k/kduan/szn_workspace/SafetyEvaluation_AfterEdit/hparams/MEMIT/mistral-7b-soc.yaml
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [01:37<03:14, 97.18s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [03:03<01:30, 90.71s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [04:21<00:00, 85.04s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [04:21<00:00, 87.22s/it]
2024-10-18 20:26:42,095 - easyeditor.editors.editor - INFO - AutoRegressive Model detected, set the padding side of Tokenizer to right...
10/18/2024 20:26:42 - INFO - easyeditor.editors.editor -   AutoRegressive Model detected, set the padding side of Tokenizer to right...
  0%|          | 0/1 [00:00<?, ?it/s]Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.42it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.42it/s]
["Who is Ismene's father? Tethys"]
  0%|          | 0/1 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple of tuples. This is deprecated and will be removed in v4.47. Please convert your cache or use an appropriate `Cache` class (https://huggingface.co/docs/transformers/kv_cache#legacy-cache-format)
MEMIT request sample: [Who is Ismene's father?] -> [ Tethys]
Cached context templates [['{}'], ['The first time I saw the movie, â€œ. {}', 'Therefore, if a person wants to be in. {}', 'Because I was in the area, I stopped. {}', 'I have always been a fan of the original. {}', 'You may have heard of this little thing called. {}']]
Computing right vector (v)
Lookup index found: 5 | Sentence: Who is Ismene's father?Teth | Token: ene
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.629 = 5.629 + 0.0 + 0.0 avg prob of [ Tethys] 0.003807462751865387
loss 3.928 = 3.799 + 0.127 + 0.001 avg prob of [ Tethys] 0.024291692301630974
loss 2.221 = 2.149 + 0.071 + 0.001 avg prob of [ Tethys] 0.12243034690618515
loss 0.962 = 0.891 + 0.069 + 0.001 avg prob of [ Tethys] 0.42451220750808716
loss 0.531 = 0.474 + 0.055 + 0.001 avg prob of [ Tethys] 0.6286247968673706
loss 0.32 = 0.277 + 0.041 + 0.001 avg prob of [ Tethys] 0.7626161575317383
loss 0.14 = 0.097 + 0.041 + 0.001 avg prob of [ Tethys] 0.9080911874771118
loss 0.059 = 0.017 + 0.041 + 0.001 avg prob of [ Tethys] 0.983383059501648
loss 0.047 = 0.006 + 0.04 + 0.001 avg prob of [ Tethys] 0.9943290948867798
Init norm 2.7829251289367676 | Delta norm 11.13170051574707 | Target norm 11.44650650024414


LAYER 4

Writing 1 key/value pair(s) into layer 4
cuda:0 cuda:0
z error tensor(11.1317, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.4.mlp.down_proj.
stats_dir:./data/stats/mistral
mistral/wikipedia_stats/model.layers.4.mlp.down_proj_float32_mom2_100.npz
filename:./data/stats/mistral/mistral/wikipedia_stats/model.layers.4.mlp.down_proj_float32_mom2_100.npz
filename:data/stats/mistral/mistral/wikipedia_stats/model.layers.4.mlp.down_proj_float32_mom2_100.npz
Computing Cov locally....
Loading cached data/stats/mistral/mistral/wikipedia_stats/model.layers.4.mlp.down_proj_float32_mom2_100.npz

  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s]
cuda:0 cuda:0
orig norm tensor(21.9081, device='cuda:0')
upd norm tensor(0.9318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
cuda:0 cuda:0
z error tensor(9.9835, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.5.mlp.down_proj.
stats_dir:./data/stats/mistral
mistral/wikipedia_stats/model.layers.5.mlp.down_proj_float32_mom2_100.npz
filename:./data/stats/mistral/mistral/wikipedia_stats/model.layers.5.mlp.down_proj_float32_mom2_100.npz
filename:data/stats/mistral/mistral/wikipedia_stats/model.layers.5.mlp.down_proj_float32_mom2_100.npz
Computing Cov locally....
Loading cached data/stats/mistral/mistral/wikipedia_stats/model.layers.5.mlp.down_proj_float32_mom2_100.npz

  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s]
cuda:0 cuda:0
orig norm tensor(21.6015, device='cuda:0')
upd norm tensor(0.8001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
cuda:0 cuda:0
z error tensor(8.3281, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.6.mlp.down_proj.
stats_dir:./data/stats/mistral
mistral/wikipedia_stats/model.layers.6.mlp.down_proj_float32_mom2_100.npz
filename:./data/stats/mistral/mistral/wikipedia_stats/model.layers.6.mlp.down_proj_float32_mom2_100.npz
filename:data/stats/mistral/mistral/wikipedia_stats/model.layers.6.mlp.down_proj_float32_mom2_100.npz
Computing Cov locally....
Loading cached data/stats/mistral/mistral/wikipedia_stats/model.layers.6.mlp.down_proj_float32_mom2_100.npz

  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s]
cuda:0 cuda:0
orig norm tensor(21.7502, device='cuda:0')
upd norm tensor(0.7897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
cuda:0 cuda:0
z error tensor(6.2534, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.7.mlp.down_proj.
stats_dir:./data/stats/mistral
mistral/wikipedia_stats/model.layers.7.mlp.down_proj_float32_mom2_100.npz
filename:./data/stats/mistral/mistral/wikipedia_stats/model.layers.7.mlp.down_proj_float32_mom2_100.npz
filename:data/stats/mistral/mistral/wikipedia_stats/model.layers.7.mlp.down_proj_float32_mom2_100.npz
Computing Cov locally....
Loading cached data/stats/mistral/mistral/wikipedia_stats/model.layers.7.mlp.down_proj_float32_mom2_100.npz

  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s]
cuda:0 cuda:0
orig norm tensor(21.6499, device='cuda:0')
upd norm tensor(0.7575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
cuda:0 cuda:0
z error tensor(3.7737, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.8.mlp.down_proj.
stats_dir:./data/stats/mistral
mistral/wikipedia_stats/model.layers.8.mlp.down_proj_float32_mom2_100.npz
filename:./data/stats/mistral/mistral/wikipedia_stats/model.layers.8.mlp.down_proj_float32_mom2_100.npz
filename:data/stats/mistral/mistral/wikipedia_stats/model.layers.8.mlp.down_proj_float32_mom2_100.npz
Computing Cov locally....
Loading cached data/stats/mistral/mistral/wikipedia_stats/model.layers.8.mlp.down_proj_float32_mom2_100.npz

  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:05<00:00, 185.76s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:05<00:00, 185.76s/it]
2024-10-18 20:29:56,451 - easyeditor.editors.editor - INFO - 0 editing: Who is Ismene's father? -> Tethys  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': "Who is Ismene's father?", 'target_new': 'Tethys', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ismene'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}
10/18/2024 20:29:56 - INFO - easyeditor.editors.editor -   0 editing: Who is Ismene's father? -> Tethys  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': "Who is Ismene's father?", 'target_new': 'Tethys', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ismene'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
cuda:0 cuda:0
orig norm tensor(21.8294, device='cuda:0')
upd norm tensor(0.8487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
entering edit_evaluation
["Who is Ismene's father? Tethys"]
Metrics Summary:  {'pre': {'rewrite_acc': 0.0}, 'post': {'rewrite_acc': 0.6666666666666666}}
--------------------------------------------------











Now we start evaluating
Model Name:  MistralForCausalLM(
  (model): MistralModel(
    (embed_tokens): Embedding(32768, 4096)
    (layers): ModuleList(
      (0-31): 32 x MistralDecoderLayer(
        (self_attn): MistralAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): MistralRotaryEmbedding()
        )
        (mlp): MistralMLP(
          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)
        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)
      )
    )
    (norm): MistralRMSNorm((4096,), eps=1e-05)
  )
  (lm_head): Linear(in_features=4096, out_features=32768, bias=False)
)
Data Path:  /home/k/kduan/szn_workspace/SafetyEvaluation_AfterEdit/data/Eval_data/merged_data_2024-10-18.json
Output Path:  /home/k/kduan/szn_workspace/SafetyEvaluation_AfterEdit/safety_evaluate/mistral/MEMIT/test_and_eval_1/part_1
0  to  200
generating!
200  to  400
generating!
400  to  600
generating!
Model Name:  MistralForCausalLM(
  (model): MistralModel(
    (embed_tokens): Embedding(32768, 4096)
    (layers): ModuleList(
      (0-31): 32 x MistralDecoderLayer(
        (self_attn): MistralAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): MistralRotaryEmbedding()
        )
        (mlp): MistralMLP(
          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)
        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)
      )
    )
    (norm): MistralRMSNorm((4096,), eps=1e-05)
  )
  (lm_head): Linear(in_features=4096, out_features=32768, bias=False)
)
Data Path:  /home/k/kduan/szn_workspace/SafetyEvaluation_AfterEdit/data/Eval_data/merged_data_2024-10-18.json
Output Path:  /home/k/kduan/szn_workspace/SafetyEvaluation_AfterEdit/safety_evaluate/mistral/MEMIT/test_and_eval_1/part_1
0  to  200
generating!
Model Name:  MistralForCausalLM(
  (model): MistralModel(
    (embed_tokens): Embedding(32768, 4096)
    (layers): ModuleList(
      (0-31): 32 x MistralDecoderLayer(
        (self_attn): MistralAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): MistralRotaryEmbedding()
        )
        (mlp): MistralMLP(
          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)
        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)
      )
    )
    (norm): MistralRMSNorm((4096,), eps=1e-05)
  )
  (lm_head): Linear(in_features=4096, out_features=32768, bias=False)
)
Data Path:  /home/k/kduan/szn_workspace/SafetyEvaluation_AfterEdit/data/Eval_data/merged_data_2024-10-18.json
Output Path:  /home/k/kduan/szn_workspace/SafetyEvaluation_AfterEdit/safety_evaluate/mistral/MEMIT/test_and_eval_1/part_1
0  to  200
generating!
200  to  400
generating!
400  to  600
generating!
600  to  800
generating!
800  to  1000
generating!
1000  to  1200
generating!
1200  to  1400
generating!
1400  to  1600
generating!
2024-10-18 20:36:14,881 - easyeditor.editors.editor - INFO - Instantiating model
10/18/2024 20:36:14 - INFO - easyeditor.editors.editor -   Instantiating model
Loading data from ../../data/Edit_data/merged_data_part_2.json
Prepare for params from /home/k/kduan/szn_workspace/SafetyEvaluation_AfterEdit/hparams/MEMIT/mistral-7b-soc.yaml
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [01:26<02:53, 86.89s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [02:33<01:14, 74.83s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [03:27<00:00, 65.42s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [03:27<00:00, 69.16s/it]
2024-10-18 20:39:43,707 - easyeditor.editors.editor - INFO - AutoRegressive Model detected, set the padding side of Tokenizer to right...
10/18/2024 20:39:43 - INFO - easyeditor.editors.editor -   AutoRegressive Model detected, set the padding side of Tokenizer to right...
  0%|          | 0/1 [00:00<?, ?it/s]Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.35it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.35it/s]
['In what fictional work would you find a character named San Theodoros? The Adventures of Sherlock Holmes']
  0%|          | 0/1 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple of tuples. This is deprecated and will be removed in v4.47. Please convert your cache or use an appropriate `Cache` class (https://huggingface.co/docs/transformers/kv_cache#legacy-cache-format)
MEMIT request sample: [In what fictional work would you find a character named San Theodoros?] -> [ The Adventures of Sherlock Holmes]
Cached context templates [['{}'], ['The first time I saw the movie, â€œ. {}', 'Therefore, if a person wants to be in. {}', 'Because I was in the area, I stopped. {}', 'I have always been a fan of the original. {}', 'You may have heard of this little thing called. {}']]
Computing right vector (v)
Lookup index found: 15 | Sentence: In what fictional work would you find a character named San Theodoros?The Adventures of Sherlock | Token: os
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 1.78 = 1.78 + 0.0 + 0.0 avg prob of [ The Adventures of Sherlock Holmes] 0.1696091890335083
loss 0.52 = 0.446 + 0.072 + 0.002 avg prob of [ The Adventures of Sherlock Holmes] 0.6427206993103027
loss 0.275 = 0.252 + 0.021 + 0.002 avg prob of [ The Adventures of Sherlock Holmes] 0.7775297164916992
loss 0.203 = 0.183 + 0.019 + 0.002 avg prob of [ The Adventures of Sherlock Holmes] 0.8336071372032166
loss 0.157 = 0.137 + 0.018 + 0.002 avg prob of [ The Adventures of Sherlock Holmes] 0.8723317980766296
loss 0.111 = 0.093 + 0.017 + 0.002 avg prob of [ The Adventures of Sherlock Holmes] 0.911736011505127
loss 0.07 = 0.05 + 0.018 + 0.002 avg prob of [ The Adventures of Sherlock Holmes] 0.9509710073471069
loss 0.047 = 0.021 + 0.024 + 0.002 avg prob of [ The Adventures of Sherlock Holmes] 0.9795498251914978
Init norm 2.554229974746704 | Delta norm 10.216919898986816 | Target norm 10.575904846191406


LAYER 4

Writing 1 key/value pair(s) into layer 4
cuda:0 cuda:0
z error tensor(10.2169, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.4.mlp.down_proj.
stats_dir:./data/stats/mistral
mistral/wikipedia_stats/model.layers.4.mlp.down_proj_float32_mom2_100.npz
filename:./data/stats/mistral/mistral/wikipedia_stats/model.layers.4.mlp.down_proj_float32_mom2_100.npz
filename:data/stats/mistral/mistral/wikipedia_stats/model.layers.4.mlp.down_proj_float32_mom2_100.npz
Computing Cov locally....
Loading cached data/stats/mistral/mistral/wikipedia_stats/model.layers.4.mlp.down_proj_float32_mom2_100.npz

  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s]
cuda:0 cuda:0
orig norm tensor(21.9081, device='cuda:0')
upd norm tensor(0.8723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
cuda:0 cuda:0
z error tensor(9.4344, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.5.mlp.down_proj.
stats_dir:./data/stats/mistral
mistral/wikipedia_stats/model.layers.5.mlp.down_proj_float32_mom2_100.npz
filename:./data/stats/mistral/mistral/wikipedia_stats/model.layers.5.mlp.down_proj_float32_mom2_100.npz
filename:data/stats/mistral/mistral/wikipedia_stats/model.layers.5.mlp.down_proj_float32_mom2_100.npz
Computing Cov locally....
Loading cached data/stats/mistral/mistral/wikipedia_stats/model.layers.5.mlp.down_proj_float32_mom2_100.npz

  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s]
cuda:0 cuda:0
orig norm tensor(21.6015, device='cuda:0')
upd norm tensor(0.7535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
cuda:0 cuda:0
z error tensor(8.1445, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.6.mlp.down_proj.
stats_dir:./data/stats/mistral
mistral/wikipedia_stats/model.layers.6.mlp.down_proj_float32_mom2_100.npz
filename:./data/stats/mistral/mistral/wikipedia_stats/model.layers.6.mlp.down_proj_float32_mom2_100.npz
filename:data/stats/mistral/mistral/wikipedia_stats/model.layers.6.mlp.down_proj_float32_mom2_100.npz
Computing Cov locally....
Loading cached data/stats/mistral/mistral/wikipedia_stats/model.layers.6.mlp.down_proj_float32_mom2_100.npz

  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s]
cuda:0 cuda:0
orig norm tensor(21.7502, device='cuda:0')
upd norm tensor(0.7570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
cuda:0 cuda:0
z error tensor(6.1220, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.7.mlp.down_proj.
stats_dir:./data/stats/mistral
mistral/wikipedia_stats/model.layers.7.mlp.down_proj_float32_mom2_100.npz
filename:./data/stats/mistral/mistral/wikipedia_stats/model.layers.7.mlp.down_proj_float32_mom2_100.npz
filename:data/stats/mistral/mistral/wikipedia_stats/model.layers.7.mlp.down_proj_float32_mom2_100.npz
Computing Cov locally....
Loading cached data/stats/mistral/mistral/wikipedia_stats/model.layers.7.mlp.down_proj_float32_mom2_100.npz

  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s]
cuda:0 cuda:0
orig norm tensor(21.6499, device='cuda:0')
upd norm tensor(0.7140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
cuda:0 cuda:0
z error tensor(3.6788, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.8.mlp.down_proj.
stats_dir:./data/stats/mistral
mistral/wikipedia_stats/model.layers.8.mlp.down_proj_float32_mom2_100.npz
filename:./data/stats/mistral/mistral/wikipedia_stats/model.layers.8.mlp.down_proj_float32_mom2_100.npz
filename:data/stats/mistral/mistral/wikipedia_stats/model.layers.8.mlp.down_proj_float32_mom2_100.npz
Computing Cov locally....
Loading cached data/stats/mistral/mistral/wikipedia_stats/model.layers.8.mlp.down_proj_float32_mom2_100.npz

  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.26s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.26s/it]
2024-10-18 20:43:22,599 - easyeditor.editors.editor - INFO - 0 editing: In what fictional work would you find a character named San Theodoros? -> The Adventures of Sherlock Holmes  

 {'pre': {'rewrite_acc': [0.5714285714285714], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'In what fictional work would you find a character named San Theodoros?', 'target_new': 'The Adventures of Sherlock Holmes', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'San Theodoros'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/18/2024 20:43:22 - INFO - easyeditor.editors.editor -   0 editing: In what fictional work would you find a character named San Theodoros? -> The Adventures of Sherlock Holmes  

 {'pre': {'rewrite_acc': [0.5714285714285714], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'In what fictional work would you find a character named San Theodoros?', 'target_new': 'The Adventures of Sherlock Holmes', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'San Theodoros'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
cuda:0 cuda:0
orig norm tensor(21.8294, device='cuda:0')
upd norm tensor(0.7883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
entering edit_evaluation
['In what fictional work would you find a character named San Theodoros? The Adventures of Sherlock Holmes']
Metrics Summary:  {'pre': {'rewrite_acc': 0.5714285714285714}, 'post': {'rewrite_acc': 1.0}}
--------------------------------------------------











Now we start evaluating
Model Name:  MistralForCausalLM(
  (model): MistralModel(
    (embed_tokens): Embedding(32768, 4096)
    (layers): ModuleList(
      (0-31): 32 x MistralDecoderLayer(
        (self_attn): MistralAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): MistralRotaryEmbedding()
        )
        (mlp): MistralMLP(
          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)
        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)
      )
    )
    (norm): MistralRMSNorm((4096,), eps=1e-05)
  )
  (lm_head): Linear(in_features=4096, out_features=32768, bias=False)
)
Data Path:  /home/k/kduan/szn_workspace/SafetyEvaluation_AfterEdit/data/Eval_data/merged_data_2024-10-18.json
Output Path:  /home/k/kduan/szn_workspace/SafetyEvaluation_AfterEdit/safety_evaluate/mistral/MEMIT/test_and_eval_1/part_2
0  to  200
generating!
200  to  400
generating!
400  to  600
generating!
Model Name:  MistralForCausalLM(
  (model): MistralModel(
    (embed_tokens): Embedding(32768, 4096)
    (layers): ModuleList(
      (0-31): 32 x MistralDecoderLayer(
        (self_attn): MistralAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): MistralRotaryEmbedding()
        )
        (mlp): MistralMLP(
          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)
        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)
      )
    )
    (norm): MistralRMSNorm((4096,), eps=1e-05)
  )
  (lm_head): Linear(in_features=4096, out_features=32768, bias=False)
)
Data Path:  /home/k/kduan/szn_workspace/SafetyEvaluation_AfterEdit/data/Eval_data/merged_data_2024-10-18.json
Output Path:  /home/k/kduan/szn_workspace/SafetyEvaluation_AfterEdit/safety_evaluate/mistral/MEMIT/test_and_eval_1/part_2
0  to  200
generating!
Model Name:  MistralForCausalLM(
  (model): MistralModel(
    (embed_tokens): Embedding(32768, 4096)
    (layers): ModuleList(
      (0-31): 32 x MistralDecoderLayer(
        (self_attn): MistralAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): MistralRotaryEmbedding()
        )
        (mlp): MistralMLP(
          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)
        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)
      )
    )
    (norm): MistralRMSNorm((4096,), eps=1e-05)
  )
  (lm_head): Linear(in_features=4096, out_features=32768, bias=False)
)
Data Path:  /home/k/kduan/szn_workspace/SafetyEvaluation_AfterEdit/data/Eval_data/merged_data_2024-10-18.json
Output Path:  /home/k/kduan/szn_workspace/SafetyEvaluation_AfterEdit/safety_evaluate/mistral/MEMIT/test_and_eval_1/part_2
0  to  200
generating!
200  to  400
generating!
400  to  600
generating!
600  to  800
generating!
800  to  1000
generating!
1000  to  1200
generating!
1200  to  1400
generating!
1400  to  1600
generating!
2024-10-18 20:50:01,278 - easyeditor.editors.editor - INFO - Instantiating model
10/18/2024 20:50:01 - INFO - easyeditor.editors.editor -   Instantiating model
Loading data from ../../data/Edit_data/merged_data_part_0.json
Prepare for params from /home/k/kduan/szn_workspace/SafetyEvaluation_AfterEdit/hparams/MEMIT/mistral-7b-soc.yaml
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [01:22<02:44, 82.17s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [02:47<01:24, 84.26s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [03:29<00:00, 64.86s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [03:29<00:00, 69.89s/it]
2024-10-18 20:53:32,217 - easyeditor.editors.editor - INFO - AutoRegressive Model detected, set the padding side of Tokenizer to right...
10/18/2024 20:53:32 - INFO - easyeditor.editors.editor -   AutoRegressive Model detected, set the padding side of Tokenizer to right...
  0%|          | 0/10 [00:00<?, ?it/s]Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
 10%|â–ˆ         | 1/10 [00:00<00:06,  1.35it/s] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:00<00:01,  4.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:01<00:00,  6.36it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:01<00:00,  8.23it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:01<00:00,  9.68it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  7.16it/s]
['Which family does Epaspidoceras belong to? Noctuidae']
['What species is ZIC3 specific to? male']
['What voice type is Louise Grandjean? mezzo soprano']
['Who is listed as Wang Jipeng father? Wang Chonghua']
['What was the name of Charlotte of Schaumburg-Lippe mother? Charlotte of Bourbon-Parma']
['What constellation is home to Butterfly Cluster? Orion']
['The father of Juan MarÃ­a Bordaberry is whom? Gabrielle Bordaberry']
["What level is Javan surili's iucn conservation status? critically threatened"]
['What day was USA-199 launched? 20 December 2007']
['What was the record label of Runaway Sunday? Motown']
  0%|          | 0/10 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple of tuples. This is deprecated and will be removed in v4.47. Please convert your cache or use an appropriate `Cache` class (https://huggingface.co/docs/transformers/kv_cache#legacy-cache-format)
MEMIT request sample: [Which family does Epaspidoceras belong to?] -> [ Noctuidae]
Cached context templates [['{}'], ['The first time I saw the movie, â€œ. {}', 'Therefore, if a person wants to be in. {}', 'Because I was in the area, I stopped. {}', 'I have always been a fan of the original. {}', 'You may have heard of this little thing called. {}']]
Computing right vector (v)
Lookup index found: 8 | Sentence: Which family does Epaspidoceras belong to?Noctu | Token: eras
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 4.275 = 4.275 + 0.0 + 0.0 avg prob of [ Noctuidae] 0.015306051820516586
loss 2.902 = 2.814 + 0.087 + 0.002 avg prob of [ Noctuidae] 0.06592585146427155
loss 1.318 = 1.249 + 0.068 + 0.002 avg prob of [ Noctuidae] 0.2951580286026001
loss 0.722 = 0.504 + 0.216 + 0.002 avg prob of [ Noctuidae] 0.607269287109375
loss 0.731 = 0.662 + 0.067 + 0.002 avg prob of [ Noctuidae] 0.5208069086074829
loss 0.267 = 0.197 + 0.069 + 0.002 avg prob of [ Noctuidae] 0.8224095106124878
loss 0.067 = 0.007 + 0.059 + 0.002 avg prob of [ Noctuidae] 0.993486762046814
loss 0.052 = 0.004 + 0.047 + 0.002 avg prob of [ Noctuidae] 0.9960102438926697
loss 0.044 = 0.003 + 0.039 + 0.002 avg prob of [ Noctuidae] 0.9974510073661804
Init norm 2.5527379512786865 | Delta norm 10.210952758789062 | Target norm 10.555188179016113


LAYER 4

Writing 1 key/value pair(s) into layer 4
cuda:0 cuda:0
z error tensor(10.2110, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.4.mlp.down_proj.
stats_dir:./data/stats/mistral
mistral/wikipedia_stats/model.layers.4.mlp.down_proj_float32_mom2_100.npz
filename:./data/stats/mistral/mistral/wikipedia_stats/model.layers.4.mlp.down_proj_float32_mom2_100.npz
filename:data/stats/mistral/mistral/wikipedia_stats/model.layers.4.mlp.down_proj_float32_mom2_100.npz
Computing Cov locally....
Loading cached data/stats/mistral/mistral/wikipedia_stats/model.layers.4.mlp.down_proj_float32_mom2_100.npz

  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s]
cuda:0 cuda:0
orig norm tensor(21.9081, device='cuda:0')
upd norm tensor(0.8169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
cuda:0 cuda:0
z error tensor(9.3605, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.5.mlp.down_proj.
stats_dir:./data/stats/mistral
mistral/wikipedia_stats/model.layers.5.mlp.down_proj_float32_mom2_100.npz
filename:./data/stats/mistral/mistral/wikipedia_stats/model.layers.5.mlp.down_proj_float32_mom2_100.npz
filename:data/stats/mistral/mistral/wikipedia_stats/model.layers.5.mlp.down_proj_float32_mom2_100.npz
Computing Cov locally....
Loading cached data/stats/mistral/mistral/wikipedia_stats/model.layers.5.mlp.down_proj_float32_mom2_100.npz

  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s]
cuda:0 cuda:0
orig norm tensor(21.6015, device='cuda:0')
upd norm tensor(0.7935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
cuda:0 cuda:0
z error tensor(8.0861, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.6.mlp.down_proj.
stats_dir:./data/stats/mistral
mistral/wikipedia_stats/model.layers.6.mlp.down_proj_float32_mom2_100.npz
filename:./data/stats/mistral/mistral/wikipedia_stats/model.layers.6.mlp.down_proj_float32_mom2_100.npz
filename:data/stats/mistral/mistral/wikipedia_stats/model.layers.6.mlp.down_proj_float32_mom2_100.npz
Computing Cov locally....
Loading cached data/stats/mistral/mistral/wikipedia_stats/model.layers.6.mlp.down_proj_float32_mom2_100.npz

  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s]
cuda:0 cuda:0
orig norm tensor(21.7502, device='cuda:0')
upd norm tensor(0.7769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
cuda:0 cuda:0
z error tensor(6.1932, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.7.mlp.down_proj.
stats_dir:./data/stats/mistral
mistral/wikipedia_stats/model.layers.7.mlp.down_proj_float32_mom2_100.npz
filename:./data/stats/mistral/mistral/wikipedia_stats/model.layers.7.mlp.down_proj_float32_mom2_100.npz
filename:data/stats/mistral/mistral/wikipedia_stats/model.layers.7.mlp.down_proj_float32_mom2_100.npz
Computing Cov locally....
Loading cached data/stats/mistral/mistral/wikipedia_stats/model.layers.7.mlp.down_proj_float32_mom2_100.npz

  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s]
cuda:0 cuda:0
orig norm tensor(21.6499, device='cuda:0')
upd norm tensor(0.7781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
cuda:0 cuda:0
z error tensor(3.8429, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.8.mlp.down_proj.
stats_dir:./data/stats/mistral
mistral/wikipedia_stats/model.layers.8.mlp.down_proj_float32_mom2_100.npz
filename:./data/stats/mistral/mistral/wikipedia_stats/model.layers.8.mlp.down_proj_float32_mom2_100.npz
filename:data/stats/mistral/mistral/wikipedia_stats/model.layers.8.mlp.down_proj_float32_mom2_100.npz
Computing Cov locally....
Loading cached data/stats/mistral/mistral/wikipedia_stats/model.layers.8.mlp.down_proj_float32_mom2_100.npz

  0%|          | 0/1 [00:00<?, ?it/s][A  0%|          | 0/1 [00:00<?, ?it/s]
 10%|â–ˆ         | 1/10 [04:05<36:53, 245.92s/it] 20%|â–ˆâ–ˆ        | 2/10 [04:19<14:32, 109.04s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [04:28<07:24, 63.55s/it]  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [04:39<04:16, 42.71s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [04:48<02:33, 30.80s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [04:59<01:34, 23.74s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [05:07<00:56, 18.80s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [05:19<00:33, 16.52s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [05:29<00:14, 14.65s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [05:37<00:00, 12.53s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [05:37<00:00, 33.76s/it]
2024-10-18 20:59:21,822 - easyeditor.editors.editor - INFO - 0 editing: Which family does Epaspidoceras belong to? -> Noctuidae  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'Which family does Epaspidoceras belong to?', 'target_new': 'Noctuidae', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Epaspidoceras'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/18/2024 20:59:21 - INFO - easyeditor.editors.editor -   0 editing: Which family does Epaspidoceras belong to? -> Noctuidae  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'Which family does Epaspidoceras belong to?', 'target_new': 'Noctuidae', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Epaspidoceras'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-18 20:59:21,898 - easyeditor.editors.editor - INFO - 1 editing: What species is ZIC3 specific to? -> male  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'What species is ZIC3 specific to?', 'target_new': 'male', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'ZIC3'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/18/2024 20:59:21 - INFO - easyeditor.editors.editor -   1 editing: What species is ZIC3 specific to? -> male  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'What species is ZIC3 specific to?', 'target_new': 'male', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'ZIC3'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-18 20:59:21,971 - easyeditor.editors.editor - INFO - 2 editing: What voice type is Louise Grandjean? -> mezzo soprano  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'What voice type is Louise Grandjean?', 'target_new': 'mezzo soprano', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Louise Grandjean'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/18/2024 20:59:21 - INFO - easyeditor.editors.editor -   2 editing: What voice type is Louise Grandjean? -> mezzo soprano  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'What voice type is Louise Grandjean?', 'target_new': 'mezzo soprano', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Louise Grandjean'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-18 20:59:22,043 - easyeditor.editors.editor - INFO - 3 editing: Who is listed as Wang Jipeng father? -> Wang Chonghua  

 {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'Who is listed as Wang Jipeng father?', 'target_new': 'Wang Chonghua', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Wang Jipeng'}, 'post': {'rewrite_acc': [0.4], 'locality': {}, 'portability': {}}}
10/18/2024 20:59:22 - INFO - easyeditor.editors.editor -   3 editing: Who is listed as Wang Jipeng father? -> Wang Chonghua  

 {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'Who is listed as Wang Jipeng father?', 'target_new': 'Wang Chonghua', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Wang Jipeng'}, 'post': {'rewrite_acc': [0.4], 'locality': {}, 'portability': {}}}
2024-10-18 20:59:22,118 - easyeditor.editors.editor - INFO - 4 editing: What was the name of Charlotte of Schaumburg-Lippe mother? -> Charlotte of Bourbon-Parma  

 {'pre': {'rewrite_acc': [0.5714285714285714], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'What was the name of Charlotte of Schaumburg-Lippe mother?', 'target_new': 'Charlotte of Bourbon-Parma', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Charlotte of Schaumburg-Lippe'}, 'post': {'rewrite_acc': [0.7142857142857143], 'locality': {}, 'portability': {}}}
10/18/2024 20:59:22 - INFO - easyeditor.editors.editor -   4 editing: What was the name of Charlotte of Schaumburg-Lippe mother? -> Charlotte of Bourbon-Parma  

 {'pre': {'rewrite_acc': [0.5714285714285714], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'What was the name of Charlotte of Schaumburg-Lippe mother?', 'target_new': 'Charlotte of Bourbon-Parma', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Charlotte of Schaumburg-Lippe'}, 'post': {'rewrite_acc': [0.7142857142857143], 'locality': {}, 'portability': {}}}
2024-10-18 20:59:22,190 - easyeditor.editors.editor - INFO - 5 editing: What constellation is home to Butterfly Cluster? -> Orion  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'What constellation is home to Butterfly Cluster?', 'target_new': 'Orion', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Butterfly Cluster'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/18/2024 20:59:22 - INFO - easyeditor.editors.editor -   5 editing: What constellation is home to Butterfly Cluster? -> Orion  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'What constellation is home to Butterfly Cluster?', 'target_new': 'Orion', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Butterfly Cluster'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-18 20:59:22,263 - easyeditor.editors.editor - INFO - 6 editing: The father of Juan MarÃ­a Bordaberry is whom? -> Gabrielle Bordaberry  

 {'pre': {'rewrite_acc': [0.5714285714285714], 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'The father of Juan MarÃ­a Bordaberry is whom?', 'target_new': 'Gabrielle Bordaberry', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Juan MarÃ­a Bordaberry'}, 'post': {'rewrite_acc': [0.8571428571428571], 'locality': {}, 'portability': {}}}
10/18/2024 20:59:22 - INFO - easyeditor.editors.editor -   6 editing: The father of Juan MarÃ­a Bordaberry is whom? -> Gabrielle Bordaberry  

 {'pre': {'rewrite_acc': [0.5714285714285714], 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'The father of Juan MarÃ­a Bordaberry is whom?', 'target_new': 'Gabrielle Bordaberry', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Juan MarÃ­a Bordaberry'}, 'post': {'rewrite_acc': [0.8571428571428571], 'locality': {}, 'portability': {}}}
2024-10-18 20:59:22,337 - easyeditor.editors.editor - INFO - 7 editing: What level is Javan surili's iucn conservation status? -> critically threatened  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': "What level is Javan surili's iucn conservation status?", 'target_new': 'critically threatened', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Javan surili'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/18/2024 20:59:22 - INFO - easyeditor.editors.editor -   7 editing: What level is Javan surili's iucn conservation status? -> critically threatened  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': "What level is Javan surili's iucn conservation status?", 'target_new': 'critically threatened', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Javan surili'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-18 20:59:22,410 - easyeditor.editors.editor - INFO - 8 editing: What day was USA-199 launched? -> 20 December 2007  

 {'pre': {'rewrite_acc': [0.4444444444444444], 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'What day was USA-199 launched?', 'target_new': '20 December 2007', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'USA-199'}, 'post': {'rewrite_acc': [0.8888888888888888], 'locality': {}, 'portability': {}}}
10/18/2024 20:59:22 - INFO - easyeditor.editors.editor -   8 editing: What day was USA-199 launched? -> 20 December 2007  

 {'pre': {'rewrite_acc': [0.4444444444444444], 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'What day was USA-199 launched?', 'target_new': '20 December 2007', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'USA-199'}, 'post': {'rewrite_acc': [0.8888888888888888], 'locality': {}, 'portability': {}}}
2024-10-18 20:59:22,482 - easyeditor.editors.editor - INFO - 9 editing: What was the record label of Runaway Sunday? -> Motown  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'What was the record label of Runaway Sunday?', 'target_new': 'Motown', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Runaway Sunday'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}
10/18/2024 20:59:22 - INFO - easyeditor.editors.editor -   9 editing: What was the record label of Runaway Sunday? -> Motown  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'What was the record label of Runaway Sunday?', 'target_new': 'Motown', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Runaway Sunday'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
cuda:0 cuda:0
orig norm tensor(21.8294, device='cuda:0')
upd norm tensor(0.8805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [What species is ZIC3 specific to?] -> [ male]
Computing right vector (v)
Lookup index found: 6 | Sentence: What species is ZIC3 specific to? | Token: 3
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 11.631 = 11.631 + 0.0 + 0.0 avg prob of [ male] 1.3574841432273388e-05
loss 7.742 = 7.667 + 0.074 + 0.002 avg prob of [ male] 0.0010208503808826208
loss 4.906 = 4.744 + 0.161 + 0.002 avg prob of [ male] 0.0125672472640872
loss 0.702 = 0.152 + 0.548 + 0.002 avg prob of [ male] 0.8620690107345581
loss 2.079 = 1.601 + 0.477 + 0.002 avg prob of [ male] 0.2316989153623581
loss 0.383 = 0.195 + 0.186 + 0.002 avg prob of [ male] 0.823340117931366
loss 0.362 = 0.169 + 0.191 + 0.002 avg prob of [ male] 0.8450350761413574
loss 0.213 = 0.063 + 0.148 + 0.002 avg prob of [ male] 0.9391660690307617
loss 0.159 = 0.028 + 0.129 + 0.002 avg prob of [ male] 0.9726079702377319
loss 0.143 = 0.015 + 0.126 + 0.002 avg prob of [ male] 0.9846301078796387
loss 0.125 = 0.011 + 0.113 + 0.002 avg prob of [ male] 0.9894366264343262
loss 0.118 = 0.008 + 0.108 + 0.002 avg prob of [ male] 0.9918578863143921
loss 0.113 = 0.007 + 0.105 + 0.002 avg prob of [ male] 0.9932821989059448
loss 0.11 = 0.006 + 0.103 + 0.002 avg prob of [ male] 0.9942891597747803
loss 0.108 = 0.005 + 0.101 + 0.002 avg prob of [ male] 0.9951299428939819
loss 0.106 = 0.004 + 0.1 + 0.002 avg prob of [ male] 0.9958407878875732
loss 0.103 = 0.004 + 0.098 + 0.002 avg prob of [ male] 0.9964077472686768
loss 0.101 = 0.003 + 0.096 + 0.002 avg prob of [ male] 0.9968403577804565
loss 0.099 = 0.003 + 0.094 + 0.002 avg prob of [ male] 0.9971659183502197
loss 0.096 = 0.003 + 0.092 + 0.002 avg prob of [ male] 0.9974087476730347
loss 0.09 = 0.002 + 0.086 + 0.002 avg prob of [ male] 0.9975802302360535
loss 0.076 = 0.002 + 0.072 + 0.002 avg prob of [ male] 0.997658371925354
loss 0.048 = 0.002 + 0.044 + 0.002 avg prob of [ male] 0.997563362121582
Init norm 2.531914472579956 | Delta norm 10.127657890319824 | Target norm 10.626641273498535


LAYER 4

Writing 1 key/value pair(s) into layer 4
cuda:0 cuda:0
z error tensor(10.1277, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.4.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(21.9233, device='cuda:0')
upd norm tensor(0.9138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
cuda:0 cuda:0
z error tensor(9.3551, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.5.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(21.6152, device='cuda:0')
upd norm tensor(0.7719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
cuda:0 cuda:0
z error tensor(8.0009, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.6.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(21.7630, device='cuda:0')
upd norm tensor(0.7564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
cuda:0 cuda:0
z error tensor(6.0538, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.7.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(21.6628, device='cuda:0')
upd norm tensor(0.7023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
cuda:0 cuda:0
z error tensor(3.6437, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.8.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(21.8458, device='cuda:0')
upd norm tensor(0.8068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [What voice type is Louise Grandjean?] -> [ mezzo soprano]
Computing right vector (v)
Lookup index found: 8 | Sentence: What voice type is Louise Grandjean?mezzo sopr | Token: an
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 2.524 = 2.524 + 0.0 + 0.0 avg prob of [ mezzo soprano] 0.09220533072948456
loss 1.46 = 1.377 + 0.081 + 0.002 avg prob of [ mezzo soprano] 0.253424733877182
loss 0.879 = 0.832 + 0.045 + 0.002 avg prob of [ mezzo soprano] 0.43601807951927185
loss 0.845 = 0.811 + 0.033 + 0.002 avg prob of [ mezzo soprano] 0.4767487943172455
loss 0.937 = 0.923 + 0.013 + 0.002 avg prob of [ mezzo soprano] 0.3988967537879944
loss 0.718 = 0.705 + 0.012 + 0.002 avg prob of [ mezzo soprano] 0.49524497985839844
loss 0.381 = 0.358 + 0.021 + 0.002 avg prob of [ mezzo soprano] 0.6996464133262634
loss 0.174 = 0.122 + 0.05 + 0.002 avg prob of [ mezzo soprano] 0.8850504755973816
loss 0.201 = 0.181 + 0.018 + 0.002 avg prob of [ mezzo soprano] 0.8345659971237183
loss 0.088 = 0.067 + 0.019 + 0.002 avg prob of [ mezzo soprano] 0.9355282187461853
loss 0.038 = 0.017 + 0.02 + 0.002 avg prob of [ mezzo soprano] 0.9831568598747253
Init norm 2.383054494857788 | Delta norm 9.532217979431152 | Target norm 9.779389381408691


LAYER 4

Writing 1 key/value pair(s) into layer 4
cuda:0 cuda:0
z error tensor(9.5322, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.4.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(21.9426, device='cuda:0')
upd norm tensor(0.8575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
cuda:0 cuda:0
z error tensor(8.8054, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.5.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(21.6283, device='cuda:0')
upd norm tensor(0.7509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
cuda:0 cuda:0
z error tensor(7.8618, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.6.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(21.7752, device='cuda:0')
upd norm tensor(0.7761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
cuda:0 cuda:0
z error tensor(6.1378, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.7.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(21.6730, device='cuda:0')
upd norm tensor(0.7829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
cuda:0 cuda:0
z error tensor(3.8553, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.8.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(21.8596, device='cuda:0')
upd norm tensor(0.8687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [Who is listed as Wang Jipeng father?] -> [ Wang Chonghua]
Computing right vector (v)
Lookup index found: 8 | Sentence: Who is listed as Wang Jipeng father?Wang Chongh | Token: eng
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.392 = 6.392 + 0.0 + 0.0 avg prob of [ Wang Chonghua] 0.0017634117975831032
loss 5.268 = 5.215 + 0.051 + 0.002 avg prob of [ Wang Chonghua] 0.005668061785399914
loss 4.738 = 4.705 + 0.031 + 0.002 avg prob of [ Wang Chonghua] 0.009106257930397987
loss 3.676 = 3.632 + 0.042 + 0.002 avg prob of [ Wang Chonghua] 0.02656676433980465
loss 1.978 = 1.919 + 0.057 + 0.002 avg prob of [ Wang Chonghua] 0.1506141871213913
loss 4.132 = 4.087 + 0.043 + 0.002 avg prob of [ Wang Chonghua] 0.016912341117858887
loss 2.458 = 2.401 + 0.055 + 0.002 avg prob of [ Wang Chonghua] 0.09205132722854614
loss 1.414 = 1.359 + 0.053 + 0.002 avg prob of [ Wang Chonghua] 0.26467132568359375
loss 0.89 = 0.814 + 0.074 + 0.002 avg prob of [ Wang Chonghua] 0.45804914832115173
loss 0.641 = 0.562 + 0.077 + 0.002 avg prob of [ Wang Chonghua] 0.5856441259384155
loss 1.042 = 0.966 + 0.074 + 0.002 avg prob of [ Wang Chonghua] 0.38641589879989624
loss 0.103 = 0.045 + 0.055 + 0.002 avg prob of [ Wang Chonghua] 0.9559485912322998
loss 0.09 = 0.019 + 0.069 + 0.002 avg prob of [ Wang Chonghua] 0.9807747602462769
loss 0.049 = 0.014 + 0.033 + 0.002 avg prob of [ Wang Chonghua] 0.9858757853507996
Init norm 2.200829029083252 | Delta norm 8.803316116333008 | Target norm 9.033897399902344


LAYER 4

Writing 1 key/value pair(s) into layer 4
cuda:0 cuda:0
z error tensor(8.8033, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.4.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(21.9593, device='cuda:0')
upd norm tensor(0.8036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
cuda:0 cuda:0
z error tensor(7.9950, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.5.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(21.6404, device='cuda:0')
upd norm tensor(0.6966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
cuda:0 cuda:0
z error tensor(6.9268, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.6.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(21.7877, device='cuda:0')
upd norm tensor(0.6878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
cuda:0 cuda:0
z error tensor(5.4893, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.7.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(21.6857, device='cuda:0')
upd norm tensor(0.6941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
cuda:0 cuda:0
z error tensor(3.4695, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.8.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(21.8756, device='cuda:0')
upd norm tensor(0.7801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [What was the name of Charlotte of Schaumburg-Lippe mother?] -> [ Charlotte of Bourbon-Parma]
Computing right vector (v)
Lookup index found: 15 | Sentence: What was the name of Charlotte of Schaumburg-Lippe mother?Charlotte of Bourbon-Par | Token: pe
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 3.971 = 3.971 + 0.0 + 0.0 avg prob of [ Charlotte of Bourbon-Parma] 0.01969505101442337
loss 3.424 = 3.37 + 0.052 + 0.002 avg prob of [ Charlotte of Bourbon-Parma] 0.035665012896060944
loss 2.879 = 2.871 + 0.007 + 0.002 avg prob of [ Charlotte of Bourbon-Parma] 0.05791714787483215
loss 3.189 = 3.181 + 0.006 + 0.002 avg prob of [ Charlotte of Bourbon-Parma] 0.043788980692625046
loss 2.064 = 2.055 + 0.007 + 0.002 avg prob of [ Charlotte of Bourbon-Parma] 0.12968501448631287
loss 1.593 = 1.586 + 0.006 + 0.002 avg prob of [ Charlotte of Bourbon-Parma] 0.20700493454933167
loss 0.794 = 0.786 + 0.006 + 0.002 avg prob of [ Charlotte of Bourbon-Parma] 0.4559646546840668
loss 0.196 = 0.188 + 0.006 + 0.002 avg prob of [ Charlotte of Bourbon-Parma] 0.8288917541503906
loss 0.04 = 0.031 + 0.008 + 0.002 avg prob of [ Charlotte of Bourbon-Parma] 0.9699475169181824
Init norm 2.3227055072784424 | Delta norm 9.29082202911377 | Target norm 9.653301239013672


LAYER 4

Writing 1 key/value pair(s) into layer 4
cuda:0 cuda:0
z error tensor(9.2908, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.4.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(21.9739, device='cuda:0')
upd norm tensor(0.7756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
cuda:0 cuda:0
z error tensor(8.6114, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.5.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(21.6507, device='cuda:0')
upd norm tensor(0.7117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
cuda:0 cuda:0
z error tensor(7.5058, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.6.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(21.7976, device='cuda:0')
upd norm tensor(0.7366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
cuda:0 cuda:0
z error tensor(5.9199, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.7.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(21.6957, device='cuda:0')
upd norm tensor(0.7250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
cuda:0 cuda:0
z error tensor(3.6873, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.8.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(21.8887, device='cuda:0')
upd norm tensor(0.8156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [What constellation is home to Butterfly Cluster?] -> [ Orion]
Computing right vector (v)
Lookup index found: 11 | Sentence: What constellation is home to Butterfly Cluster?Or | Token: uster
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 2.745 = 2.745 + 0.0 + 0.0 avg prob of [ Orion] 0.08081072568893433
loss 1.544 = 1.422 + 0.12 + 0.002 avg prob of [ Orion] 0.25517988204956055
loss 3.273 = 3.23 + 0.041 + 0.002 avg prob of [ Orion] 0.07917357981204987
loss 0.644 = 0.601 + 0.041 + 0.002 avg prob of [ Orion] 0.5573833584785461
loss 0.462 = 0.435 + 0.026 + 0.002 avg prob of [ Orion] 0.6593137979507446
loss 0.281 = 0.258 + 0.02 + 0.002 avg prob of [ Orion] 0.7778348922729492
loss 0.171 = 0.151 + 0.018 + 0.002 avg prob of [ Orion] 0.8614002466201782
loss 0.116 = 0.097 + 0.017 + 0.002 avg prob of [ Orion] 0.9077063798904419
loss 0.086 = 0.069 + 0.016 + 0.002 avg prob of [ Orion] 0.9336687922477722
loss 0.068 = 0.052 + 0.014 + 0.002 avg prob of [ Orion] 0.9492197036743164
loss 0.056 = 0.042 + 0.012 + 0.002 avg prob of [ Orion] 0.9591954946517944
loss 0.047 = 0.035 + 0.011 + 0.002 avg prob of [ Orion] 0.9660968780517578
Init norm 2.2753870487213135 | Delta norm 9.101548194885254 | Target norm 9.424592971801758


LAYER 4

Writing 1 key/value pair(s) into layer 4
cuda:0 cuda:0
z error tensor(9.1015, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.4.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(21.9876, device='cuda:0')
upd norm tensor(0.7814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
cuda:0 cuda:0
z error tensor(8.4527, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.5.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(21.6614, device='cuda:0')
upd norm tensor(0.6889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
cuda:0 cuda:0
z error tensor(7.4752, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.6.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(21.8088, device='cuda:0')
upd norm tensor(0.7150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
cuda:0 cuda:0
z error tensor(5.9287, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.7.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(21.7066, device='cuda:0')
upd norm tensor(0.7317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
cuda:0 cuda:0
z error tensor(3.7423, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.8.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(21.9027, device='cuda:0')
upd norm tensor(0.8216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The father of Juan MarÃ­a Bordaberry is whom?] -> [ Gabrielle Bordaberry]
Computing right vector (v)
Lookup index found: 9 | Sentence: The father of Juan MarÃ­a Bordaberry is whom?Gabrielle Bordab | Token: erry
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 3.267 = 3.267 + 0.0 + 0.0 avg prob of [ Gabrielle Bordaberry] 0.03891375660896301
loss 2.929 = 2.852 + 0.075 + 0.001 avg prob of [ Gabrielle Bordaberry] 0.059969715774059296
loss 1.84 = 1.803 + 0.036 + 0.001 avg prob of [ Gabrielle Bordaberry] 0.16785304248332977
loss 0.685 = 0.657 + 0.026 + 0.001 avg prob of [ Gabrielle Bordaberry] 0.5208392143249512
loss 0.187 = 0.161 + 0.025 + 0.001 avg prob of [ Gabrielle Bordaberry] 0.8516463041305542
loss 0.078 = 0.052 + 0.025 + 0.001 avg prob of [ Gabrielle Bordaberry] 0.9499289989471436
loss 0.035 = 0.009 + 0.024 + 0.001 avg prob of [ Gabrielle Bordaberry] 0.9910232424736023
Init norm 2.9109232425689697 | Delta norm 11.643692970275879 | Target norm 12.106639862060547


LAYER 4

Writing 1 key/value pair(s) into layer 4
cuda:0 cuda:0
z error tensor(11.6437, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.4.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(22.0015, device='cuda:0')
upd norm tensor(1.0260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
cuda:0 cuda:0
z error tensor(10.5869, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.5.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(21.6715, device='cuda:0')
upd norm tensor(0.9071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
cuda:0 cuda:0
z error tensor(9.0223, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.6.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(21.8188, device='cuda:0')
upd norm tensor(0.8973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
cuda:0 cuda:0
z error tensor(6.8243, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.7.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(21.7174, device='cuda:0')
upd norm tensor(0.8689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
cuda:0 cuda:0
z error tensor(4.1912, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.8.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(21.9164, device='cuda:0')
upd norm tensor(0.9654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [What level is Javan surili's iucn conservation status?] -> [ critically threatened]
Computing right vector (v)
Lookup index found: 7 | Sentence: What level is Javan surili's iucn conservation status?critically | Token: ili
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 7.126 = 7.126 + 0.0 + 0.0 avg prob of [ critically threatened] 0.0008384231477975845
loss 4.85 = 4.765 + 0.084 + 0.002 avg prob of [ critically threatened] 0.008622132241725922
loss 4.496 = 4.446 + 0.048 + 0.002 avg prob of [ critically threatened] 0.012050754390656948
loss 2.683 = 2.658 + 0.024 + 0.002 avg prob of [ critically threatened] 0.07027407735586166
loss 0.99 = 0.965 + 0.024 + 0.002 avg prob of [ critically threatened] 0.3815285861492157
loss 0.2 = 0.166 + 0.033 + 0.002 avg prob of [ critically threatened] 0.85085129737854
loss 0.086 = 0.02 + 0.065 + 0.002 avg prob of [ critically threatened] 0.980526328086853
loss 0.084 = 0.027 + 0.056 + 0.002 avg prob of [ critically threatened] 0.9737175703048706
loss 0.068 = 0.01 + 0.057 + 0.002 avg prob of [ critically threatened] 0.9901851415634155
loss 0.062 = 0.004 + 0.057 + 0.002 avg prob of [ critically threatened] 0.9961261749267578
loss 0.06 = 0.002 + 0.056 + 0.002 avg prob of [ critically threatened] 0.9981107711791992
loss 0.057 = 0.001 + 0.055 + 0.002 avg prob of [ critically threatened] 0.9988352656364441
loss 0.05 = 0.001 + 0.048 + 0.002 avg prob of [ critically threatened] 0.9990970492362976
loss 0.049 = 0.001 + 0.046 + 0.002 avg prob of [ critically threatened] 0.9991242289543152
Init norm 2.5260396003723145 | Delta norm 10.104158401489258 | Target norm 10.433158874511719


LAYER 4

Writing 1 key/value pair(s) into layer 4
cuda:0 cuda:0
z error tensor(10.1042, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.4.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(22.0254, device='cuda:0')
upd norm tensor(0.9332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
cuda:0 cuda:0
z error tensor(9.2103, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.5.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(21.6898, device='cuda:0')
upd norm tensor(0.7660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
cuda:0 cuda:0
z error tensor(7.9146, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.6.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(21.8366, device='cuda:0')
upd norm tensor(0.7671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
cuda:0 cuda:0
z error tensor(6.0555, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.7.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(21.7339, device='cuda:0')
upd norm tensor(0.7467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
cuda:0 cuda:0
z error tensor(3.7408, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.8.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(21.9373, device='cuda:0')
upd norm tensor(0.8288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [What day was USA-199 launched?] -> [ 20 December 2007]
Computing right vector (v)
Lookup index found: 8 | Sentence: What day was USA-199 launched?20 December 200 | Token: 9
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 3.514 = 3.514 + 0.0 + 0.0 avg prob of [ 20 December 2007] 0.030013859272003174
loss 3.364 = 3.225 + 0.137 + 0.002 avg prob of [ 20 December 2007] 0.04005734249949455
loss 2.666 = 2.66 + 0.004 + 0.002 avg prob of [ 20 December 2007] 0.07065488398075104
loss 1.74 = 1.708 + 0.03 + 0.002 avg prob of [ 20 December 2007] 0.18421941995620728
loss 2.228 = 2.183 + 0.043 + 0.002 avg prob of [ 20 December 2007] 0.11291138827800751
loss 1.091 = 1.081 + 0.008 + 0.002 avg prob of [ 20 December 2007] 0.345229834318161
loss 0.647 = 0.594 + 0.051 + 0.002 avg prob of [ 20 December 2007] 0.5601732730865479
loss 1.331 = 1.308 + 0.022 + 0.002 avg prob of [ 20 December 2007] 0.2749614119529724
loss 0.531 = 0.516 + 0.013 + 0.002 avg prob of [ 20 December 2007] 0.5974261164665222
loss 0.243 = 0.207 + 0.034 + 0.002 avg prob of [ 20 December 2007] 0.8133467435836792
loss 0.076 = 0.06 + 0.013 + 0.002 avg prob of [ 20 December 2007] 0.9416646361351013
loss 0.038 = 0.004 + 0.032 + 0.002 avg prob of [ 20 December 2007] 0.9961680173873901
Init norm 2.0072343349456787 | Delta norm 8.028937339782715 | Target norm 8.309772491455078


LAYER 4

Writing 1 key/value pair(s) into layer 4
cuda:0 cuda:0
z error tensor(8.0289, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.4.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(22.0450, device='cuda:0')
upd norm tensor(0.7442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
cuda:0 cuda:0
z error tensor(7.5222, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.5.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(21.7029, device='cuda:0')
upd norm tensor(0.6590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
cuda:0 cuda:0
z error tensor(6.6217, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.6.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(21.8493, device='cuda:0')
upd norm tensor(0.6768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
cuda:0 cuda:0
z error tensor(5.2622, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.7.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(21.7457, device='cuda:0')
upd norm tensor(0.6778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
cuda:0 cuda:0
z error tensor(3.3567, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.8.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(21.9520, device='cuda:0')
upd norm tensor(0.7875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [What was the record label of Runaway Sunday?] -> [ Motown]
Computing right vector (v)
Lookup index found: 9 | Sentence: What was the record label of Runaway Sunday?Mot | Token: Sunday
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.362 = 6.362 + 0.0 + 0.0 avg prob of [ Motown] 0.0017584379529580474
loss 4.298 = 4.252 + 0.044 + 0.002 avg prob of [ Motown] 0.01710764318704605
loss 2.534 = 2.502 + 0.03 + 0.002 avg prob of [ Motown] 0.08747388422489166
loss 2.203 = 2.143 + 0.058 + 0.002 avg prob of [ Motown] 0.12553289532661438
loss 2.354 = 2.308 + 0.045 + 0.002 avg prob of [ Motown] 0.10790454596281052
loss 1.078 = 1.051 + 0.025 + 0.002 avg prob of [ Motown] 0.377399206161499
loss 0.043 = 0.016 + 0.025 + 0.002 avg prob of [ Motown] 0.9843120574951172
Init norm 2.103609085083008 | Delta norm 8.414436340332031 | Target norm 8.713704109191895


LAYER 4

Writing 1 key/value pair(s) into layer 4
cuda:0 cuda:0
z error tensor(8.4144, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.4.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(22.0575, device='cuda:0')
upd norm tensor(0.7757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
cuda:0 cuda:0
z error tensor(7.7948, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.5.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(21.7121, device='cuda:0')
upd norm tensor(0.6388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
cuda:0 cuda:0
z error tensor(6.8490, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.6.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(21.8589, device='cuda:0')
upd norm tensor(0.6619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
cuda:0 cuda:0
z error tensor(5.3699, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.7.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(21.7551, device='cuda:0')
upd norm tensor(0.6417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
cuda:0 cuda:0
z error tensor(3.3660, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for _home_k_kduan_szn_workspace_hf_cache_soc_mistral-7b-instruct-v0.3 @ model.layers.8.mlp.down_proj.
cuda:0 cuda:0
orig norm tensor(21.9649, device='cuda:0')
upd norm tensor(0.7210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
entering edit_evaluation
['Which family does Epaspidoceras belong to? Noctuidae']
entering edit_evaluation
['What species is ZIC3 specific to? male']
entering edit_evaluation
['What voice type is Louise Grandjean? mezzo soprano']
entering edit_evaluation
['Who is listed as Wang Jipeng father? Wang Chonghua']
entering edit_evaluation
['What was the name of Charlotte of Schaumburg-Lippe mother? Charlotte of Bourbon-Parma']
entering edit_evaluation
['What constellation is home to Butterfly Cluster? Orion']
entering edit_evaluation
['The father of Juan MarÃ­a Bordaberry is whom? Gabrielle Bordaberry']
entering edit_evaluation
["What level is Javan surili's iucn conservation status? critically threatened"]
entering edit_evaluation
['What day was USA-199 launched? 20 December 2007']
entering edit_evaluation
['What was the record label of Runaway Sunday? Motown']
Metrics Summary:  {'pre': {'rewrite_acc': 0.4037301587301587}, 'post': {'rewrite_acc': 0.8360317460317461}}
--------------------------------------------------











Now we start evaluating
Model Name:  MistralForCausalLM(
  (model): MistralModel(
    (embed_tokens): Embedding(32768, 4096)
    (layers): ModuleList(
      (0-31): 32 x MistralDecoderLayer(
        (self_attn): MistralAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): MistralRotaryEmbedding()
        )
        (mlp): MistralMLP(
          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)
        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)
      )
    )
    (norm): MistralRMSNorm((4096,), eps=1e-05)
  )
  (lm_head): Linear(in_features=4096, out_features=32768, bias=False)
)
Data Path:  /home/k/kduan/szn_workspace/SafetyEvaluation_AfterEdit/data/Eval_data/merged_data_2024-10-18.json
Output Path:  /home/k/kduan/szn_workspace/SafetyEvaluation_AfterEdit/safety_evaluate/mistral/MEMIT/test_and_eval_10/part_0
0  to  200
generating!
200  to  400
generating!
400  to  600
generating!
Model Name:  MistralForCausalLM(
  (model): MistralModel(
    (embed_tokens): Embedding(32768, 4096)
    (layers): ModuleList(
      (0-31): 32 x MistralDecoderLayer(
        (self_attn): MistralAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): MistralRotaryEmbedding()
        )
        (mlp): MistralMLP(
          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)
        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)
      )
    )
    (norm): MistralRMSNorm((4096,), eps=1e-05)
  )
  (lm_head): Linear(in_features=4096, out_features=32768, bias=False)
)
Data Path:  /home/k/kduan/szn_workspace/SafetyEvaluation_AfterEdit/data/Eval_data/merged_data_2024-10-18.json
Output Path:  /home/k/kduan/szn_workspace/SafetyEvaluation_AfterEdit/safety_evaluate/mistral/MEMIT/test_and_eval_10/part_0
0  to  200
generating!
Model Name:  MistralForCausalLM(
  (model): MistralModel(
    (embed_tokens): Embedding(32768, 4096)
    (layers): ModuleList(
      (0-31): 32 x MistralDecoderLayer(
        (self_attn): MistralAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): MistralRotaryEmbedding()
        )
        (mlp): MistralMLP(
          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)
        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)
      )
    )
    (norm): MistralRMSNorm((4096,), eps=1e-05)
  )
  (lm_head): Linear(in_features=4096, out_features=32768, bias=False)
)
Data Path:  /home/k/kduan/szn_workspace/SafetyEvaluation_AfterEdit/data/Eval_data/merged_data_2024-10-18.json
Output Path:  /home/k/kduan/szn_workspace/SafetyEvaluation_AfterEdit/safety_evaluate/mistral/MEMIT/test_and_eval_10/part_0
0  to  200
generating!
200  to  400
generating!
400  to  600
generating!
600  to  800
generating!
800  to  1000
generating!
1000  to  1200
generating!
1200  to  1400
generating!
1400  to  1600
generating!
2024-10-18 21:08:04,417 - easyeditor.editors.editor - INFO - Instantiating model
10/18/2024 21:08:04 - INFO - easyeditor.editors.editor -   Instantiating model
slurmstepd-xgph4: error: *** JOB 350911 ON xgph4 CANCELLED AT 2024-10-18T21:08:05 ***
